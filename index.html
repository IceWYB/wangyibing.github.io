<!DOCTYPE html>

<HTML>
<HEAD>
  <META content="IE=5.0000" http-equiv="X-UA-Compatible">
  <META name="description" content="Yibing Wang's home page"> 
  <META http-equiv="Content-Type" content="text/html; charset=gb2312">
  <LINK href="files/doc.css" 
    rel="stylesheet" type="text/css"> 
  <TITLE>Yibing Wang</TITLE> 
  <META name="GENERATOR" content="MSHTML 11.00.10570.1001">
</HEAD>


<BODY> 
  <DIV id="layout-content" style="margin-top: 25px;">
  <TABLE>
    <TBODY>
    <TR>
      <TD width="670">
        <DIV id="toptitle">
        <H1>Yibing Wang &nbsp;</H1></DIV>
        <H3>Ph.D. candidate</H3>
        <BR>School of Electronic, Electric and Communication System
        <BR>University of Chinese Academy of Science
        <BR>Beijing, China.
        <BR>
        <BR> Email:  
        <A href="mailto:wangyibing18@mails.ucas.ac.cn"> wangyibing18@mails.ucas.ac.cn</A>; 
        <BR> Github: 
        <A href="https://github.com/IceWYB">https://github.com/IceWYB</A>;
        <BR> Google scholar:
        <A href="https://scholar.google.co.uk/citations?user=zNk0c_0AAAAJ&hl=zh-CN&oi=sra">https://scholar.google.co.uk/citations?user=zNk0c_0AAAAJ&hl=zh-CN&oi=sra</A>
        <BR><BR></P>
      </TD>
      <TD>
        <IMG width="150" src="files/personal_photo.jpg" border="0">
      </TD>
    </TR>
    <TR></TR></TBODY>
  </TABLE>
  <DIV id="layout-content" style="margin-top: 25px;">


  <H2>Biography</H2>
  <P> I am a Ph.D. candidate in the School of Electronic, Electric and Communication System, University of Chinese Academy of Science</A>, 
    advised by <A href="https://scholar.google.com/citations?user=XqdpqNcAAAAJ">Prof. Jianbin Jiao</A>.
    I got a B.E. degree in the University of Chinese Academy of Science in June 2022.
  </P>

  <P>My research interests include computer vision and deep learning, specifically for multimodal learning.</P>

  <H2>Academic Services</H2>
    <P> Journal Reviewer: IJCV, ICML, CVPR, etc.</P>

  <!-- <H2>News</H2>
    <P> [2024.08] <b>Kangaroo: A Powerful Video-Language Model Supporting Long-context Video Input </b> is available on <A href="https://arxiv.org/pdf/2408.15542"> Arkiv</A>. </P>
     -->
  <H2>Publications</H2>
    <table class="pub_table">
    <!-- <tbody> -->
      <tr>
        <td class="pub_td1"><img src="files/kangaroo.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast; Jiajun Liu, &ast; <u>Yibing Wang</u>, Hanghang Ma, Xiaoping Wu, Xiaoqi Ma, Xiaoming Wei, Jianbin Jiao, Enhua Wu, and Jie Hu
          <br><b>Kangaroo: A Powerful Video-Language Model Supporting Long-context Video Input</b>
          <br>
          [<a href="https://arxiv.org/pdf/2408.15542">Paper</a>]
          [<a href="https://github.com/KangarooGroup/Kangaroo">Code</a>]
          [<a href="https://huggingface.co/KangarooGroup/kangaroo">Model</a>]
          [<a href="https://kangaroogroup.github.io/Kangaroo.github.io">Blog</a>]
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/odyssey.png" class="papericon"></td>
        <td 
          class="pub_td2">Gong, Kaixiong and Feng, Kaituo and Li, Bohao and <u>Yibing Wang</u> and Cheng, Mofan and Yang, Shijia and Han, Jiaming and Wang, Benyou and Bai, Yutong and Yang, Zhuoran
          <br><b>AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?</b>
          <br>
          [<a href="https://arxiv.org/pdf/2412.02611">Paper</a>]
          [<a href="https://github.com/AV-Odyssey/AV-Odyssey">Code</a>]
          [<a href="https://huggingface.co/datasets/AV-Odyssey/AV_Odyssey_Bench">Dataset</a>]
          [<a href="https://av-odyssey.github.io">Blog</a>]
          <br>
        </td>
      </tr>

</BODY>
</HTML>
